# -*- coding: utf-8 -*-
"""HD202406077.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1x63oPX0jcFMVEBnkG1bCRXcxyAdvFdWC
"""

#pip install xgboost lightgbm catboost tensorflow

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from wordcloud import WordCloud
import re
import nltk
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier, VotingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report
from xgboost import XGBClassifier
import lightgbm as lgb
from catboost import CatBoostClassifier

nltk.download('stopwords')
nltk.download('wordnet')

file_path = '/content/Youtube Playlist Comments with Sentiments (1).csv'  # Path to your dataset
df = pd.read_csv(file_path)

df.head()

df.dropna(subset=['Sentiments'], inplace=True)

lemmatizer = WordNetLemmatizer()
stop_words = set(stopwords.words('english'))

def preprocess_text(text):
    text = text.lower()  # Lowercase
    text = re.sub(r'[^a-zA-Z\s]', '', text)  # Remove special characters and numbers
    text = ' '.join([lemmatizer.lemmatize(word) for word in text.split() if word not in stop_words])  # Lemmatize and remove stopwords
    return text

df['Processed_Comment'] = df['Comment'].apply(preprocess_text)

df['Sentiments'] = df['Sentiments'].map({'positive': 1, 'negative': 0, 'neutral': 2})

lemmatizer = WordNetLemmatizer()
stop_words = set(stopwords.words('english'))

def preprocess_text(text):
    text = text.lower()  # Lowercase
    text = re.sub(r'[^a-zA-Z\s]', '', text)  # Remove special characters and numbers
    text = ' '.join([lemmatizer.lemmatize(word) for word in text.split() if word not in stop_words])  # Lemmatize and remove stopwords
    return text

plt.figure(figsize=(8, 6))
sns.countplot(x='Sentiments', data=df, palette='coolwarm')
plt.title('Sentiment Distribution')
plt.xticks([0, 1, 2], ['Negative', 'Positive', 'Neutral'])
plt.show()

import matplotlib.pyplot as plt
from wordcloud import WordCloud

for sentiment, color in zip(['positive', 'negative', 'neutral'], ['Greens', 'Reds', 'Blues']):
    sentiment_words = ' '.join(df[df['Sentiments'] == {'positive': 1, 'negative': 0, 'neutral': 2}[sentiment]]['Processed_Comment'])
    wordcloud = WordCloud(width=800, height=400, background_color='white', colormap=color).generate(sentiment_words)

    plt.figure(figsize=(10, 6))
    plt.imshow(wordcloud, interpolation='bilinear')
    plt.axis('off')
    plt.title(f'WordCloud for {sentiment.capitalize()} Sentiments')
    plt.show()

df

# @title Reply Count vs Sentiments

from matplotlib import pyplot as plt
df.plot(kind='scatter', x='Reply Count', y='Sentiments', s=32, alpha=.8)
plt.gca().spines[['top', 'right',]].set_visible(False)

# @title Likes vs Reply Count

from matplotlib import pyplot as plt
df.plot(kind='scatter', x='Likes', y='Reply Count', s=32, alpha=.8)
plt.gca().spines[['top', 'right',]].set_visible(False)

# @title Lecture vs Likes

from matplotlib import pyplot as plt
df.plot(kind='scatter', x='Lecture', y='Likes', s=32, alpha=.8)
plt.gca().spines[['top', 'right',]].set_visible(False)

# @title Likes

from matplotlib import pyplot as plt
df['Likes'].plot(kind='hist', bins=20, title='Likes')
plt.gca().spines[['top', 'right',]].set_visible(False)

# @title Lecture

from matplotlib import pyplot as plt
df['Lecture'].plot(kind='hist', bins=20, title='Lecture')
plt.gca().spines[['top', 'right',]].set_visible(False)

tfidf = TfidfVectorizer(max_features=10000, ngram_range=(1, 2), stop_words='english')
X = tfidf.fit_transform(df['Processed_Comment'])
y = df['Sentiments']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report

models = {
    "Logistic Regression": LogisticRegression(max_iter=1000),
    "Random Forest": RandomForestClassifier(),
    "SVM": SVC(),
    "Naive Bayes": MultinomialNB(),
    "XGBoost": XGBClassifier(eval_metric='mlogloss'),
    "LightGBM": lgb.LGBMClassifier(),
    "CatBoost": CatBoostClassifier(learning_rate=0.1, depth=6, iterations=100, verbose=0)
}

performance = {}

# Impute missing values in y_train (replace NaN with most frequent value)
from sklearn.impute import SimpleImputer
imputer = SimpleImputer(strategy='most_frequent')
y_train_imputed = imputer.fit_transform(y_train.values.reshape(-1, 1))  # Reshape for the imputer
y_train_imputed = y_train_imputed.ravel()  # Flatten back to 1D array

# Handle potential missing values in y_test as well
y_test_imputed = imputer.transform(y_test.values.reshape(-1, 1))
y_test_imputed = y_test_imputed.ravel()

# Train and evaluate each model
for model_name, model in models.items():
    # Use the imputed y_train for model fitting
    model.fit(X_train, y_train_imputed)
    y_pred = model.predict(X_test)

    # Evaluate the model using imputed y_test
    accuracy = accuracy_score(y_test_imputed, y_pred)
    precision = precision_score(y_test_imputed, y_pred, average='weighted')
    recall = recall_score(y_test_imputed, y_pred, average='weighted')
    f1 = f1_score(y_test_imputed, y_pred, average='weighted')

    # Save the performance metrics
    performance[model_name] = {
        'Accuracy': accuracy,
        'Precision': precision,
        'Recall': recall,
        'F1 Score': f1
    }

    # Print classification report
    print(f"\n{model_name} Classification Report:")
    print(classification_report(y_test_imputed, y_pred, target_names=['Negative', 'Positive', 'Neutral']))

performance_df = pd.DataFrame(performance).T

# Plot the model performance - Accuracy
plt.figure(figsize=(10, 6))
sns.barplot(x=performance_df.index, y=performance_df['Accuracy'], palette='viridis')
plt.title('Model Comparison Based on Accuracy')
plt.ylabel('Accuracy Score')
plt.xlabel('Model')
plt.show()

plt.figure(figsize=(10, 6))
performance_df.plot(kind='bar', figsize=(12, 8), title="Model Performance Metrics Comparison")
plt.ylabel('Score')
plt.show()

sv = models['SVM']
y_pred_log_reg = sv.predict(X_test)

# Impute missing values in y_test (if any)
from sklearn.impute import SimpleImputer
imputer = SimpleImputer(strategy='most_frequent')
y_test_imputed = imputer.fit_transform(y_test.values.reshape(-1, 1))
y_test_imputed = y_test_imputed.ravel()

# Now use imputed y_test for confusion matrix
conf_mat = confusion_matrix(y_test_imputed, y_pred_log_reg)

plt.figure(figsize=(8, 6))
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues', xticklabels=['Negative', 'Positive', 'Neutral'], yticklabels=['Negative', 'Positive', 'Neutral'])
plt.title('Confusion Matrix - Logistic Regression')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

# -*- coding: utf-8 -*-
"""HD202406077_Mannual.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1auEijrPheCyUAfa9mIMTJi9qxksfFvd1
"""

pip install xgboost lightgbm catboost tensorflow

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from wordcloud import WordCloud
import re
import nltk
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier, VotingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report
from xgboost import XGBClassifier
import lightgbm as lgb
from catboost import CatBoostClassifier

nltk.download('stopwords')
nltk.download('wordnet')

file_path = '/content/HD202406077-excel_2_.csv'  # Path to your dataset
df = pd.read_csv(file_path)

df.head()

df.dropna(subset=['Sentiments'], inplace=True)

lemmatizer = WordNetLemmatizer()
stop_words = set(stopwords.words('english'))

def preprocess_text(text):
    text = text.lower()  # Lowercase
    text = re.sub(r'[^a-zA-Z\s]', '', text)  # Remove special characters and numbers
    text = ' '.join([lemmatizer.lemmatize(word) for word in text.split() if word not in stop_words])  # Lemmatize and remove stopwords
    return text

df['Processed_Comment'] = df['Comment'].apply(preprocess_text)

df['Sentiments'] = df['Sentiments'].map({'Positive': 1, 'Negative': 0, 'Neutral': 2})

lemmatizer = WordNetLemmatizer()
stop_words = set(stopwords.words('english'))

def preprocess_text(text):
    text = text.lower()  # Lowercase
    text = re.sub(r'[^a-zA-Z\s]', '', text)  # Remove special characters and numbers
    text = ' '.join([lemmatizer.lemmatize(word) for word in text.split() if word not in stop_words])  # Lemmatize and remove stopwords
    return text

plt.figure(figsize=(8, 6))
sns.countplot(x='Sentiments', data=df, palette='coolwarm')
plt.title('Sentiment Distribution')
plt.xticks([0, 1, 2], ['Negative', 'Positive', 'Neutral'])
plt.show()

import matplotlib.pyplot as plt
from wordcloud import WordCloud

for sentiment, color in zip(['positive', 'negative', 'neutral'], ['Greens', 'Reds', 'Blues']):
    sentiment_words = ' '.join(df[df['Sentiments'] == {'positive': 1, 'negative': 0, 'neutral': 2}[sentiment]]['Processed_Comment'])
    wordcloud = WordCloud(width=800, height=400, background_color='white', colormap=color).generate(sentiment_words)

    plt.figure(figsize=(10, 6))
    plt.imshow(wordcloud, interpolation='bilinear')
    plt.axis('off')
    plt.title(f'WordCloud for {sentiment.capitalize()} Sentiments')
    plt.show()

df

# @title Lecture vs Likes

from matplotlib import pyplot as plt
df.plot(kind='scatter', x='Lecture', y='Likes', s=32, alpha=.8)
plt.gca().spines[['top', 'right',]].set_visible(False)

# @title Likes

from matplotlib import pyplot as plt
df['Likes'].plot(kind='hist', bins=20, title='Likes')
plt.gca().spines[['top', 'right',]].set_visible(False)

# @title Lecture

from matplotlib import pyplot as plt
df['Lecture'].plot(kind='hist', bins=20, title='Lecture')
plt.gca().spines[['top', 'right',]].set_visible(False)

tfidf = TfidfVectorizer(max_features=10000, ngram_range=(1, 2), stop_words='english')
X = tfidf.fit_transform(df['Processed_Comment'])
y = df['Sentiments']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report

models = {
    "Logistic Regression": LogisticRegression(max_iter=1000),
    "Random Forest": RandomForestClassifier(),
    "SVM": SVC(),
    "Naive Bayes": MultinomialNB(),
    "XGBoost": XGBClassifier(eval_metric='mlogloss'),
    "LightGBM": lgb.LGBMClassifier(),
    "CatBoost": CatBoostClassifier(learning_rate=0.1, depth=6, iterations=100, verbose=0)
}

performance = {}

# Impute missing values in y_train (replace NaN with most frequent value)
from sklearn.impute import SimpleImputer
imputer = SimpleImputer(strategy='most_frequent')
y_train_imputed = imputer.fit_transform(y_train.values.reshape(-1, 1))  # Reshape for the imputer
y_train_imputed = y_train_imputed.ravel()  # Flatten back to 1D array

# Handle potential missing values in y_test as well
y_test_imputed = imputer.transform(y_test.values.reshape(-1, 1))
y_test_imputed = y_test_imputed.ravel()

# Adjust class labels to start from 0
y_train_imputed = y_train_imputed - 1
y_test_imputed = y_test_imputed - 1

# Train and evaluate each model
for model_name, model in models.items():
    # Use the imputed y_train for model fitting
    model.fit(X_train, y_train_imputed)  # Use adjusted labels
    y_pred = model.predict(X_test)

    # Evaluate the model using imputed y_test
    accuracy = accuracy_score(y_test_imputed, y_pred)  # Use adjusted labels
    precision = precision_score(y_test_imputed, y_pred, average='weighted')
    recall = recall_score(y_test_imputed, y_pred, average='weighted')
    f1 = f1_score(y_test_imputed, y_pred, average='weighted')

    # Save the performance metrics
    performance[model_name] = {
        'Accuracy': accuracy,
        'Precision': precision,
        'Recall': recall,
        'F1 Score': f1
    }

    # Print classification report
    print(f"\n{model_name} Classification Report:")
    print(classification_report(y_test_imputed, y_pred, target_names=['Negative', 'Positive', 'Neutral']))

performance_df = pd.DataFrame(performance).T

# Plot the model performance - Accuracy
plt.figure(figsize=(10, 6))
sns.barplot(x=performance_df.index, y=performance_df['Accuracy'], palette='viridis')
plt.title('Model Comparison Based on Accuracy')
plt.ylabel('Accuracy Score')
plt.xlabel('Model')
plt.show()

plt.figure(figsize=(10, 6))
performance_df.plot(kind='bar', figsize=(12, 8), title="Model Performance Metrics Comparison")
plt.ylabel('Score')
plt.show()

sv = models['SVM']
y_pred_log_reg = sv.predict(X_test)

# Impute missing values in y_test (if any)
from sklearn.impute import SimpleImputer
imputer = SimpleImputer(strategy='most_frequent')
y_test_imputed = imputer.fit_transform(y_test.values.reshape(-1, 1))
y_test_imputed = y_test_imputed.ravel()

# Now use imputed y_test for confusion matrix
conf_mat = confusion_matrix(y_test_imputed, y_pred_log_reg)

plt.figure(figsize=(8, 6))
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues', xticklabels=['Negative', 'Positive', 'Neutral'], yticklabels=['Negative', 'Positive', 'Neutral'])
plt.title('Confusion Matrix - Logistic Regression')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()